# 目录

- [1.携程推荐算法面试题8道](#1.携程推荐算法面试题8道)

  - 讲一讲推荐系统包含哪些流程？
  - Transformer 位置编码是什么？
  - QKV 注意力公式为什么除以根号 d
  - 简单讲讲 GCN
  - 简单讲讲RNN
  - RNN 里的参数有什么特点？
  - Dropout 是怎么做的？有什么作用？推理和训练时 Dropout 的区别？如果推理也用 dropout 会怎么样？
  - 讲讲 BN？BN 训练和推理什么区别？有什么用？

- [2.趣玩科技推荐算法面试题9道](#2.趣玩科技推荐算法面试题9道)

  - 二分类的分类损失函数？
  - 多分类的分类损失函数(Softmax)？
  - 关于梯度下降的sgdm,adagrad，介绍一下。
  - 为什么不用 MSE 分类用交叉熵？
  - yolov5 相比于之前增加的特性有哪些？
  - 可以介绍一下 attention 机制吗？
  - 关于 attention 机制，三个矩阵 Q,K,V的作用是什么？
  - 介绍一下文本检测 EAST？
  - 编程题(讲思路)：给定两个字符串 s,t，在 s 字符串中找到包含 t 字符串的最小字符串。

- [3.快手推荐算法面试题7道](#3.快手推荐算法面试题7道)

  - 为什么 self-attention 可以堆叠多层，有什么作用？
  - 多头有什么作用？如果想让不同头之间有交互，可以怎么做？
  - 讲一讲多目标优化，MMoE 怎么设计？如果权重为 1,0,0 这样全部集中在某一个专家上该怎么办？
  - 介绍一下神经网络的优化器有哪些。
  - 介绍一下推荐算法的链路流程。
  - 介绍一下神经网络的初始化方法。
  - 讲一讲推荐算法序列建模的模型。

- [4.华为NLP算法面试题9道](#4.华为NLP算法面试题9道)

  -  **NLP中常见的分词方法有哪些？**
  - 讲一下BERT的结构？
  - 自然语言处理有哪些任务？
  - L1，L2正则化的区别，岭回归是L1正则化还是L2正则化？
  - 怎么处理类别不平衡？
  - 模型提速的方法有哪些？
  - 了解数据挖掘的方法嘛？
  - 了解对比学习嘛？
  - 说一下广度优先遍历和深度优先遍历？

- [5.联想算法面试题9道](#5.联想算法面试题9道)

  - 分类问题的交叉熵是什么？
  - 分类问题是否可以用MSE？
  - 推荐系统中，相比于余弦相似度，是否可以用欧几里得距离判断相似度？
  - 过拟合怎么处理？
  - L1、L2正则化的效果、区别、原理？
  - Dropout的原理、在训练和测试时的区别？
  - SGD、Adam、动量优化的SGD？
  - Adam和动量优化的SGD效率上的区别？
  - 推荐系统中，如何进行负采样？

- [6.字节电商CV算法实习岗面试题8道](#6.字节电商CV算法实习岗面试题8道)

  - 如何解决类别极度不平衡的问题？
  - 说下 Transformer 模型
  - 说下 Focal Loss
  - 介绍下深度可分离卷积和传统卷积的区别
  - 如何防止过拟合
  - BN 在训练和测试的时候的区别？可以防止过拟合吗？
  - 什么是 AUC？
  - 卷积核计算公式

- [7.中兴算法面试题5道](#7.中兴算法面试题5道)

  - 介绍一下矩阵分析课程中的内容
  - 介绍一下内积和外积
  - 参数估计时，极大似然和贝叶斯的区别
  -  EM算法的原理
  - CLIP框架

- [8.Cver整理](#8.Cver整理)
  - TensorRT优化的流程
  
  - 介绍YOLOv4-YOLOv8
  
  - 密集行人检测遮挡问题怎么解决
  
  - 为什么U-Net在医学图像上表现好
  
  - 自动驾驶中检测模型如何针对Corner case优化
  
  - 训练网络时怎么判断有没有过拟合、欠拟合
  
  - GBDT和Adaboost的区别
  
  - 神经网络的初始化方法
  
  - DETR中匈牙利匹配算法的具体流程
  
  - 为什么transformer中要用layerNorm
  
  -  为什么self-attention可以堆叠多层，有什么作用
  
  - 介绍常用的聚类算法(KMeans,DBSCAN, Mean shift)
  
  - Canny算子的流程
  
  - NMS的缺点及其改进工作
  
  - 怎么判断连通域是否相邻
  
  - Segmentation和Matting的区别
  
  - 介绍SVM和逻辑回归
  
  - 如何检测未知目标
  
  - 多卡的BN如何实现同步
  
  - 图像边缘检测算子有哪些
  
  - 各种回归损失的计算以及优缺点
  
  - Transformer相比于CNN的优缺点
  
  - LN和BN
  
  - 介绍RLHF
  
  - 介绍MoE和变体
  
  - 介绍LoRA和变体
  
  - LoRA参数更新的机制
  
  - 如何减轻LLM中的幻觉现象
  
  - MLM和MIM的关系和区别
  
  - Stable Diffusion的技术原理
  
  - 解决LLM Hallucination的方法
  
  - Occupancy预测的出发点是什么
  
  - 介绍RWKV，Mamba和Mamba v2
  
  - 2D图像预训练怎么迁移到3D点云任务
  
  -  为什么现在的LLM都是decoder-only架构
  
  -  Transformer训练深有什么问题，怎么解决
  
  - 现在车道线检测的主流的loss是什么?你有哪些想法?
  
  - 如何让 LLM基于 query和 context得到高质量的response
  
  - 为什么GAN中经常遇到mode collapse，而Diffusion比较少?
  
  - 位置编码有哪些？
  
  - ViT为什么要分patch？
  
  - Transformer训练和部署技巧
  
  - 介绍自注意力机制和数学公式
  
  - 介绍Transformer的Encoder模块
  
  - 介绍Transformer的Decoder模块
  - Transformer和Mamba（SSM）的区别
  
  - Transformer中的残差结构以及意义
  
  - 为什么Transformer适合多模态任务？
  
  - Transformer的并行化体现在哪个地方？
  
  - Transformer为什么使用多头注意力机制？
  
  - Transformer训练的Dropout是如何设定的？
  
  - Transformer 模型中的自注意力机制是如何工作的？
  
- [9.牛客整理](#9.牛客整理)
  -  BERT和GPT的区别，分别的优势
  - 大模型的发展趋势
  - 介绍一下flash attention
  - 介绍一下Group Query Attention
  - dense特征和sparse特征的区别是什么
  - mapreduce如何做10亿个数字的全局排序
  - RNN、LSTM、Transformer的区别
  - MMOE，PLE框架介绍
  - LightGBM和XGBoost的区别
  - XGBoost原理讲解
  - 随机森林如何保证每个树的随机性
  - MMoE如何保证每个专家的随机性
  - multi-head attention如何保证每个head的随机性
  -  bagging和boosting的区别
  - 介绍卷积 激活 池化 全连接层含义
  - 什么情况下可以不使用池化层
  - 决策树怎么划分特征
  - 随机森林有两种随机方式 怎么体现
  - 线性模型和非线性模型的优缺点
  - 样本数量小且特征数量多时 使用线性还是非线性模型
  - 离散特征的处理方式


<h2 id="1.携程推荐算法面试题8道">1.携程推荐算法面试题8道</h2>

###  **问题1：讲一讲推荐系统包含哪些流程？**
推荐系统的流程通常包括以下几个步骤：
- **数据收集**：收集用户行为数据（如浏览记录、购买记录、点击记录等）和物品数据（如物品特征、分类、标签等）。
- **数据预处理**：对数据进行清洗、归一化、特征提取等预处理操作。
- **特征工程**：构建用户画像和物品画像，提取有助于推荐的特征。
- **模型选择**：选择合适的推荐算法，如基于内容的推荐、协同过滤、矩阵分解、深度学习等。
- **模型训练**：使用历史数据训练推荐模型。
- **推荐生成**：根据训练好的模型生成推荐列表。
- **评估与调优**：使用评价指标（如准确率、召回率、F1-score等）评估推荐效果，并进行模型调优。
- **上线与更新**：将推荐系统上线，并定期更新模型和数据。

### 问题2：**Transformer 位置编码是什么？**
Transformer中的位置编码（Positional Encoding）是为了弥补自注意力机制中缺乏顺序信息的缺陷。位置编码有两种常见方式：
- **固定位置编码**：如原始Transformer论文中使用的正弦和余弦函数。每个位置的编码是一个固定的向量，不随训练变化。
- **可训练位置编码**：将位置编码作为可训练的参数，与模型其他参数一起训练。

### 问题3：QKV 注意力公式为什么除以根号 d
除以根号 $\( \sqrt{d_k} \)$ 的原因是为了防止内积值过大导致softmax函数的梯度消失问题。由于Q和K的维度较高，其内积的值会随 $\( d_k \)$ 增加而增大，
从而导致softmax的输出极端化（接近0或1）。除以根号 $\( \sqrt{d_k} \)$ 可以使得内积值的方差接近1，保持梯度稳定。

### 问题4：简单讲讲 GCN
GCN（Graph Convolutional Network，图卷积网络）是一种用于图数据的神经网络。GCN通过在图的节点上进行卷积操作来提取节点的特征。基本的GCN操作步骤包括：

- **邻接矩阵**：用邻接矩阵 \( A \) 表示图结构。
- **节点特征矩阵**：用矩阵 \( X \) 表示节点特征。
- **卷积操作**：将节点特征与邻接矩阵进行卷积。

### 问题5：**简单讲讲RNN**

RNN（Recurrent Neural Network，循环神经网络）是一类用于处理序列数据的神经网络。RNN通过循环结构使得网络可以在序列的每个时间步共享参数，
从而记忆和处理序列中的上下文信息。RNN的基本结构包括：
- **输入层**：接收序列的当前时间步输入。
- **隐藏层**：通过循环连接，将前一时间步的隐藏状态和当前时间步的输入一起处理，生成当前时间步的隐藏状态。
- **输出层**：生成当前时间步的输出。

### 问题6：RNN 里的参数有什么特点？

RNN的参数具有共享性，即在序列的每个时间步使用相同的一组参数。这使得RNN能够有效处理不同长度的序列，并在参数数量固定的情况下学习序列中的时间依赖关系。

### 问题7：Dropout 是怎么做的？有什么作用？推理和训练时 Dropout 的区别？如果推理也用 dropout 会怎么样？

Dropout是一种正则化技术，通过在训练过程中随机丢弃（即设置为零）一部分神经元来防止过拟合。具体步骤为：

1. 在每一层的输出中，以一定的概率 $\( p \)$ 随机丢弃一些神经元。
2. 对保留的神经元进行放大 $( \frac{1}{1-p} \)$ ，以保持总的激活值不变。

作用：通过随机丢弃神经元，减少节点之间的相互依赖，从而提高模型的泛化能力。

推理和训练时 Dropout 的区别
- **训练时**：应用Dropout，即随机丢弃神经元，并对保留的神经元进行放大。
- **推理时**：不应用Dropout，使用完整的网络。

如果推理时也用Dropout，模型的输出将变得不稳定，因为每次推理时网络结构都不同，导致结果不可预测且精度下降。


### 问题8：讲讲 BN？BN 训练和推理什么区别？有什么用？

Batch Normalization（BN）是一种加速深层神经网络训练并提高其稳定性的方法。BN通过对每一层的输入进行标准化，使得输入具有零均值和单位方差，
同时允许网络学习最优的均值和方差。

训练和推理的区别

- **训练时**：使用mini-batch的均值和方差，并更新全局均值和方差的移动平均值。
- **推理时**：使用训练过程中计算的全局均值和方差。

作用

- 减少内部协变量偏移（Internal Covariate Shift）。
- 加快训练速度。
- 提高模型的泛化能力。


<h2 id="2.趣玩科技推荐算法面试题9道">2. 趣玩科技推荐算法面试题9道</h2>

### 问题1： 二分类的分类损失函数？
二分类的分类损失函数一般采用交叉熵（Cross Entropy）损失函数，即 CE 损失函数。二分类问题的 CE 损失函数可以写成： 

$$-y \log(p) - (1 - y) \log(1 - p)$$

其中， $y$ 是真实标签， $p$ 是预测标签，取值为0或1。
    
### 问题2：多分类的分类损失函数(Softmax)？
多分类问题一般采用交叉熵损失函数与Softmax激活函数结合使用。多分类问题的交叉熵损失函数可以写成： 

$$-\sum_{i=1}^{N} y_i \log(p_i)$$

其中， $N$ 是类别的数量， $y_i$ 是第 $i$ 类的真实标签， $p_i$ 是第 $i$ 类的预测概率。

### 问题3：关于梯度下降的sgdm,adagrad，介绍一下。
SGD（Stochastic Gradient Descent）是最基础的梯度下降算法，每次迭代随机选取一个样本计算梯度并更新模型参数。
SGDM（Stochastic Gradient Descent with Momentum）在 SGD 的基础上增加了动量项，可以加速收敛。
Adagrad（Adaptive Gradient）是一种自适应学习率的梯度下降算法，它根据每个参数的梯度历史信息调整学习率，可以更好地适应不同参数的变化范围。

### 问题4：为什么不用 MSE 分类用交叉熵？
MSE （ Mean Squared Error ）损失函数对离群点敏感，而交叉熵（Cross Entropy）损失函数在分类问题中表现更好，
因为它能更好地刻画分类任务中标签概率分布与模型输出概率分布之间的差异。

### 问题5：yolov5 相比于之前增加的特性有哪些？
YOLOv5 相比于之前版本增加了一些特性，包括：使用 CSP（Cross Stage Partial）架构加速模型训练和推理；采用 Swish 激活函数代替 ReLU；
引入多尺度训练和测试，以提高目标检测的精度和召回率；引入 AutoML 技术，自动调整超参数以优化模型性能。

### 问题6：可以介绍一下 attention 机制吗？
Attention 机制是一种用于序列建模的技术，它可以自适应地对序列中的不同部分赋予不同的权重，以实现更好的特征表示。
在 Attention 机制中，通过计算查询向量与一组键值对之间的相似度，来确定每个键值对的权重，最终通过加权平均的方式得到 Attention 向量。

### 问题7：关于 attention 机制，三个矩阵 Q,K,V的作用是什么？
在 Attention 机制中，KQV 是一组与序列中每个元素对应的三个矩阵，其中 K 和 V 分别代表键和值，用于计算对应元素的权重，Q 代表查询向量，
用于确定权重分配的方式。三个矩阵 K、Q、V 在 Attention 机制中的具体作用如下：
- K（Key）矩阵：K 矩阵用于计算每个元素的权重，是一个与输入序列相同大小的矩阵。通过计算查询向量 Q 与每个元素的相似度，
确定每个元素在加权平均中所占的比例。
- Q（Query）向量：Q 向量是用来确定权重分配方式的向量，与输入序列中的每个元素都有一个对应的相似度，可以看作是一个加权的向量。
- V（Value）矩阵：V 矩阵是与输入序列相同大小的矩阵，用于给每个元素赋予一个对应的特征向量。在 Attention 机制中，
加权平均后的向量就是 V 矩阵的加权平均向量。

通过K、Q、V三个矩阵的计算，Attention机制可以自适应地为输入序列中的每个元素分配一个权重，以实现更好的特征表示。

### 问题8：介绍一下文本检测 EAST？
EAST（Efficient and Accurate Scene Text）是一种用于文本检测的神经网络模型。EAST 通过以文本行为单位直接预测文本的位置、方向和尺度，
避免了传统方法中需要多次检测和合并的过程，从而提高了文本检测的速度和精度。EAST 采用了一种新的训练方式，即以真实文本行作为训练样本，
以减少模型对背景噪声的干扰，并在测试阶段通过非极大值抑制（NMS）算法进行文本框的合并。

### 问题9：编程题(讲思路)：给定两个字符串 s,t，在 s 字符串中找到包含 t 字符串的最小字符串。
给定两个字符串 s、t，可以采用滑动窗口的方式在 s 中找到包含 t 的最小子串。具体做法如下：
- 定义两个指针 left 和 right，分别指向滑动窗口的左右边界。
- 先移动 right 指针，扩展滑动窗口，直到包含了 t 中的所有字符。
- 移动 left 指针，缩小滑动窗口，直到无法再包含 t 中的所有字符。
- 记录当前滑动窗口的长度，如果小于之前记录的长度，则更新最小长度和最小子串。
- 重复（2）到（4）步骤，直到 right 指针到达 s 的末尾为止。


<h2 id="3.快手推荐算法面试题7道">3.快手推荐算法面试题7道</h2>

### 问题1：为什么 self-attention 可以堆叠多层，有什么作用？
   Self-attention 能够捕捉输入序列中的长距离依赖关系，通过堆叠多层 self-attention，模型可以学习序列中更深层次的模式和依赖关系。
   多层 self-attention 就像神经网络中的多个隐藏层一样，使模型能够学习和表示更复杂的函数。

### 问题2：多头有什么作用？如果想让不同头之间有交互，可以怎么做？
   多头注意力（Multi-head attention）的设计是为了让模型同时学习到输入序列的不同表示。每个“头”都有自己的参数，可以学习到不同的注意力分布，
   这样可以让模型同时关注不同的特征或信息。至于不同头之间的交互，这通常在所有头的输出被拼接和线性转换之后自然实现。如果你希望在这之前增加交互，
   你可能需要设计新的结构或者机制。

### 问题3：讲一讲多目标优化，MMoE 怎么设计？如果权重为 1,0,0 这样全部集中在某一个专家上该怎么办？
   多目标优化是指优化多个目标函数，通常需要在不同目标间找到一个权衡。多门专家混合网络（MMoE, Multi-gate Mixture-of-Experts）
   是一种处理多目标优化的方法，其中每个目标都由一个专家网络来处理，而门网络则决定每个专家对最终输出的贡献。如果权重全部集中在某一个专家上，
   那么模型的输出就完全由那个专家决定。这可能在某些情况下是合理的，但在大多数情况下，你可能希望各个专家都能对输出有所贡献，
   这需要通过训练和调整权重来实现。

### 问题4：介绍一下神经网络的优化器有哪些。
   常见的神经网络优化器有：
   - 梯度下降（GD）
   - 随机梯度下降（SGD）
   - 带动量的随机梯度下降（Momentum SGD）
   - Adagrad
   - RMSProp
   - Adam
   - Adadelta
   - Nadam 等

### 问题5：介绍一下推荐算法的链路流程。
   推荐系统通常包括以下步骤：
   - 数据收集（用户行为、物品信息等）
   - 特征工程
   - 模型选择和训练
   - 推荐列表生成
   - 排序等

### 问题6：介绍一下神经网络的初始化方法。
   常见的神经网络初始化方法有：
   - 零初始化（所有权重设为 0）
   - 随机初始化（权重随机设定，如高斯初始化或均匀分布初始化）
   - Xavier/Glorot 初始化（权重初始化为均值为 0，方差为 $\( \frac{1}{n} \)$ 的正态分布或均匀分布，其中 $\( n \)$ 为输入神经元的数量）
   - He 初始化（类似于 Xavier，但方差为 $\( \frac{2}{n} \)$，适用于 ReLU 激活函数）

### 问题7：讲一讲推荐算法序列建模的模型。
   推荐算法中的序列建模通常使用序列模型来捕捉用户行为的时间依赖性。常见的序列模型有：
   - RNN（如 LSTM 和 GRU）
   - 序列到序列模型（Seq2Seq）
   - 注意力模型（如 Transformer）
   - 预训练模型（如 BERT、GPT 等）

   这些模型可以处理用户行为序列，学习用户的历史行为对他们未来行为的影响，并据此进行推荐。


<h2 id="4.华为NLP算法面试题9道">4.华为NLP算法面试题9道</h2>

### 问题1. **NLP中常见的分词方法有哪些？**
   **常见的中文分词方法包括基于规则、基于统计和基于深度学习的方法。** 其中，基于规则的方法根据预先定义的规则对文本进行切分；基于统计的方法通过统计某个词
   在语料库中出现的概率来进行分词；基于深度学习的方法则利用深度神经网络模型从大规模语料中学习分词模型。

### 问题2. **讲一下BERT的结构？**
   BERT（Bidirectional Encoder Representations from Transformers）是**一种基于Transformer模型的预训练语言模型。** 其结构由多层
   Transformer编码器组成，其中每层包含多头自注意力机制和前馈神经网络。**BERT还采用了双向训练策略，使得模型能够在不同层次、
   不同粒度下理解输入序列中的上下文信息。**

### 问题3. **自然语言处理有哪些任务？**
   自然语言处理任务包括**文本分类、命名实体识别、情感分析、机器翻译、文本生成、问答系统等。**

### 问题4. **L1，L2正则化的区别，岭回归是L1正则化还是L2正则化？**
   **L1正则化和L2正则化都是用来约束模型的复杂度，以避免过拟合。** L1正则化通过将模型参数的**绝对值之和**作为正则项，使得一些参数变为0，
   从而达到特征选择的目的；L2正则化通过将模型参数的**平方和**作为正则项，使得参数的值都变小，从而使模型更加稳定。岭回归是一种使用L2正则化的线性回归模型。

### 问题5. **怎么处理类别不平衡？**
   **类别不平衡问题可以通过过采样、欠采样、生成新样本、集成学习等方法来解决。** 过采样方法包括随机过采样、SMOTE等；欠采样方法包括随机欠采样、
   TomekLinks等；生成新样本方法包括GAN、VAE等；集成学习方法包括Bagging、Boosting等。

### 问题6. **模型提速的方法有哪些？**
   模型提速的方法包括**模型压缩、剪枝、量化、分布式训练等。** 模型压缩包括权重共享、低秩近似、深度可分离卷积等方法；
   剪枝包括通道剪枝、结构剪枝、权重剪枝等；量化包括权重量化、激活量化等；分布式训练则是利用多个计算节点共同完成模型训练任务，加速训练过程。

### 问题7. **了解数据挖掘的方法嘛？**
   数据挖掘包括**数据预处理、特征工程、模型构建和模型评估等步骤。** 其中，数据预处理包括数据清洗、数据集成、数据变换和数据规约；
   特征工程包括特征提取、特征选择和特征构建；模型构建包括选择合适的模型和模型参数调优；模型评估包括模型效果评估和模型泛化能力评估。

### 问题8. **了解对比学习嘛？**
   **对比学习是一种无监督学习方法，** 通过训练模型使得相同样本的表示更接近，不同样本的表示更远离，从而学习到更好的表示。
   对比学习通常使用对比损失函数，例如Siamese网络、Triplet网络等，用于学习数据之间的相似性和差异性。

### 问题9. **说一下广度优先遍历和深度优先遍历？**
   - **广度优先遍历（BFS）** 是一种图形搜索算法，从起点开始，依次访问与起点相邻的所有节点，再访问与这些节点相邻的所有未访问过的节点，
      直到找到目标节点或者所有节点都被访问。广度优先遍历使用队列来保存访问过的节点。
   - **深度优先遍历（DFS）** 是一种图形搜索算法，从起点开始，一直访问相邻节点，直到达到最深的节点，再返回上一级节点，继续访问其他未访问过的节点，
      直到找到目标节点或者所有节点都被访问。深度优先遍历使用栈来保存访问过的节点。与广度优先遍历相比，深度优先遍历更适用于搜索深度较深的图形。


<h2 id="5.联想算法面试题9道">5.联想算法面试题9道</h2>

### 问题1：分类问题的交叉熵是什么？
   **分类问题的交叉熵（cross-entropy）** 是一种用来衡量分类模型输出与真实标签之间差异的指标。在二分类问题中，交叉熵可以表示为以下公式：
   $$H(p, q) = -\sum_{c=1}^{2} p(c) \log(q(c))$$
   其中， $p$ 表示真实标签， $q$ 表示模型预测的标签， $N$ 表示样本数量。

### 问题2：分类问题是否可以用MSE？
   **分类问题通常不能使用均方误差（MSE）作为损失函数，** 因为分类问题中的标签通常是离散的，而MSE适用于连续变量的回归问题。
   当使用MSE作为损失函数时，模型的输出可能会超过1或小于0，这是因为MSE的计算方式不适用于概率值的范围。

### 问题3：推荐系统中，相比于余弦相似度，是否可以用欧几里得距离判断相似度？
   **在推荐系统中，通常使用余弦相似度来度量用户或物品之间的相似度。** 因为余弦相似度考虑的是向量之间的夹角，而不是向量的长度，
   因此它对于不同大小的向量比较稳健。而欧几里得距离则是考虑向量之间的长度，因此对于不同大小的向量比较敏感。

### 问题4：过拟合怎么处理？
   过拟合是指模型在训练集上表现良好，但在测试集上表现较差的现象。过拟合的常见处理方法包括：
   - **增加数据量**：通过增加训练数据来降低模型对于训练集的过度拟合。
   - **简化模型**：减少模型的参数量，简化模型的结构，降低模型的复杂度。
   - **正则化**：通过在损失函数中添加正则化项，限制模型参数的大小，从而避免模型过度拟合。常见的正则化方法包括L1正则化和L2正则化。

### 问题5：L1、L2正则化的效果、区别、原理？
   **L1正则化和L2正则化都是正则化方法，目的是通过限制模型参数的大小，降低模型的复杂度，防止过拟合。**
   - **L1正则化**： $$\( \text{L1 Regularization} = \lambda \sum |w_i| \)$$ ，会使一部分参数变为0，从而实现特征选择的效果， 适合处理稀疏数据。
   - **L2正则化**： $$\( \text{L2 Regularization} = \lambda \sum w_i^2 \)$$ ，会让所有参数都趋向于较小的值，但不会使参数为0。

### 问题6：Dropout的原理、在训练和测试时的区别？
   **Dropout是一种常用的正则化方法，** 其原理是在每次迭代中随机将一部分神经元的输出置为0，从而减少神经元之间的共适应性，防止过拟合。
   在训练时，Dropout会随机将一定比例的神经元的输出置为0，而在测试时，为了保持网络的稳定性，Dropout通常被关闭。

### 问题7：SGD、Adam、动量优化的SGD？
   **SGD（Stochastic Gradient Descent）是一种基本的梯度下降算法，使用单个样本的梯度来更新模型参数。** 
   **动量优化的SGD（Momentum SGD）** 在SGD的基础上引入了动量，使得更新方向更加平稳，收敛速度更快。
   Adam是一种基于梯度的优化算法，结合了RMSProp和动量优化的思想，
   通过维护一个梯度的指数加权移动平均和梯度平方的指数加权移动平均来自适应地调整每个参数的学习率。

### 问题8：Adam和动量优化的SGD效率上的区别？
   **Adam相对于动量优化的SGD有自适应性、速度快和可靠性高的优点。** Adam能够自适应地调整每个参数的学习率，从而在不同的参数空间下能够更加快速地收敛，
   并且对超参数的选择不太敏感。

### 问题9：推荐系统中，如何进行负采样？
   在推荐系统中，**负采样是一种重要的技术，用于构造负样本，以便训练推荐模型。** 负采样的过程通常包括计算每个物品的权重、根据权重进行采样、
   去除已有的正样本和控制负采样比例等步骤。


<h2 id="6.字节电商CV算法实习岗面试题8道">6.字节电商CV算法实习岗面试题8道</h2>

### 问题1：如何解决类别极度不平衡的问题？
- 在机器学习中，类别不平衡是指数据集中各类样本的数量差异较大，这可能导致模型对多数类过度拟合，而对少数类泛化能力差。
![](./imgs/sample_imbalance.png)

### 问题2：说下 Transformer 模型
- **Transformer 模型** 是一种基于自注意力机制的神经网络架构，广泛应用于序列到序列的任务中。Transformer 本身是一个典型的encoder-decoder模型，
Encoder端和Decoder端均有6个Block， Encoder 端的Block 包括两个模块，多头self-attention模块以及一个前馈神经网络模块；Decoder端的
Block 包括三个模块，多头self-attention模块，多头Encoder-Decoder attention交互模块，以及一个前 馈神经网络模块； 
需要注意：Encoder端和Decoder端中的每个模块都有残差层和LayerNormalization层。

### 问题3：说下 Focal Loss
- **Focal loss 是目标检测中解决正负样本严重不平衡的方法**，在标准交叉熵损失基础上修改得到的。这个函数可以通过减少易分类样本的权重，
使得模型在训练时更专注于稀疏的难分类的样本；防止大量易分类负样本在loss 中占主导地位

### 问题4：介绍下深度可分离卷积和传统卷积的区别
- **深度可分离卷积首先在每个通道上独立进行空间卷积，然后使用 $1 \times 1$ 的卷积来组合通道特征，与传统卷积相比，它大大减少了参数数量和计算量。**
- 传统的卷积是各个通道上采用不同的卷积核，然后不同的卷积核用于提取不同方面的特征。 
- 深度可分离卷积先在各个通道上采用不同的卷积核提取不同的特征，但是这样对于某个通道来说，就只提取了一方面的特征，因此在此基础上加入点卷积，
用1*1的卷积对提取特征后的特征图再次提取不同方面的 特征，最终产生和普通卷积相同的输出特征图。

### 问题5：如何防止过拟合
- 防止过拟合的方法包括：获取更多数据、数据增强、正则化（如L1、L2正则化）、Dropout、Early Stopping等。

### 问题6：BN 在训练和测试的时候的区别？可以防止过拟合吗？
- **Batch Normalization (BN) 在训练时对每个mini-batch的数据进行归一化，而在测试时使用整个训练集的统计量。**
- **BN有助于防止过拟合，因为它使得模型对于输入数据的分布变化更加鲁棒。** BN算法防止过拟合：在网络的训练中，BN的使用使得一个minibatch中所有样本都被关联在了一起，
因此网络不会从某一个训练样本中生成确定的结果，即同样一个样本的输出不再仅仅取决于样本的本身，也取 决于跟这个样本同属一个batch的其他样本，
而每次网络都是随机取batch，这样就会使得整个网络不会朝这一个方向使劲学习。一定程度上避免了过拟合。

### 问题7：什么是 AUC？
- **AUC（Area Under the Curve）是ROC曲线下的面积，用来衡量分类器的排序能力。** AUC可以解读为从所有正例中随机选取一个样本A，
再从所有负例中随机选取一个样本B，分类器将A判为正例的概率比将B判为正例的概率大的可能性。AUC反映的是分类器对样本的排序能力。
AUC越大，自然排序能力越好，即分类器将越多的正例排在负例之前。

### 问题8：卷积核计算公式
- 卷积层的输出特征图可以通过以下公式计算： 

$$Output = (W - K + 2P) / S + 1$$ 

其中 $W$ 是输入特征图的大小， $K$ 是卷积核的大小， 
$P$ 是padding的大小， $S$ 是步长。
- 如果想保持卷积前后的特征图大小相同，通常会设定padding为：

$$P = \frac{K - 1}{2}$$ 



<h2 id="7.中兴算法面试题5道">7.中兴算法面试题5道</h2>

### 问题1：介绍一下矩阵分析课程中的内容

- 矩阵基础：
  - 矩阵的定义与表示
  - 矩阵运算（加减乘，转置，逆）
  - 特殊类型的矩阵（对角矩阵、单位矩阵、对称矩阵、三角矩阵）
- 行列式与逆矩阵
- 矩阵分解
  - LU分解
  - QR分解
  - Cholesky分解
  - 奇异值分解
  - 特征值分解
- 向量空间与线性变换
  - 基与维数
  - 线性变换及其矩阵表示
  - 正交变换与正交矩阵
- 正交性与投影
  - 内积与范数
  - 向量的正交性与正交基
  - Gram-Schmidt正交化过程

### 问题2： 介绍一下内积和外积

- 内积是向量空间中的一种运算，定义了两个向量之间的“乘积”，从而引入了长度和角度的概念。

​	$<u,v>=\sum_i^nu_iv_i$

- 外积是两个向量的另一种运算，结果是一个矩阵，外积用于表示投影和线性变换

​	$u⊗v=uv^T$​

- 范数适用于测量向量大小或长度的函数，有非负性、齐次性、三角不等性



### 问题3：参数估计时，极大似然和贝叶斯的区别

- 极大似然估计是基于已经观察到的数据，通过选择最可能生成这些数据的参数值来进行估计。具体步骤为：
  - 定义似然函数$L(\theta;X)=P(X|\theta)=\prod_{i=1}^nP(x_i|\theta)$
  - 最大化似然函数来找到参数的估计值$\hat\theta$, $\hat\theta=argmax_{\theta}logL(\theta;X)$
- 贝叶斯估计是基于贝叶斯定理，通过综合先验知识和观察到的数据来进行参数估计。
  - 定义先验分布：选择一个先验分布$P(\theta)$来表达对参数$\theta$的先验知识；
  - 计算后验分布：$P(\theta|x)=\frac{P(x|\theta)P(\theta)}{P(x)}$，其中$P(x)=\int P(x|\theta)P(\theta)d\theta$
  - 参数估计：可以用后验分布的期望值$\hat\theta_{mean}=\int \theta P(\theta|x)d\theta$或者后验分布的最大值作为参数估计值

- **区别：**MLE完全基于数据，不考虑任何先验信息，假设参数值在初始时是等可能的；贝叶斯估计结合先验信息和数据进行估计，先验分布$P(\theta)$起到重要的作用。 MLE给出单点估计，即最可能的参数值；贝叶斯估计给出参数的后验分布，可以提供更加丰富的信息，包括参数的不确定性。MLE只需要最大化对数似然函数，相对简单；贝叶斯估计需要计算后验分布，有时需要复杂的数值积分或采样方法，计算复杂度高；MLE在大样本情况下具有较好的统计性质；贝叶斯估计在小样本情况下先验信息可以显著改善估计效果。



### 问题4： EM算法的原理

EM算法（Expectation-Maximization算法）是一种用于**含有隐变量（或缺失数据）的概率模型的参数估计方法**。它广泛应用于混合模型、隐马尔可夫模型等统计模型中。EM算法通过交替执行期望步骤（E步）和最大化步骤（M步）来迭代地找到模型参数的**最大似然估计**。

假设我们有观测数据 $X$和隐变量$Z$，以及参数向量 $\theta$。EM算法的目标是找到参数 $\theta$ 使得观测数据的似然函数 $P(X;\theta)$最大化。

- 初始化参数$\theta^0$
- 迭代过程：
  - E step: 计算隐变量的条件期望，使用当前参数估计$\theta^t$;$Q(\theta|\theta^t)=E_{Z|X;\theta^t}[logP(X,Z;\theta)]$
  - M step: 最大化条件期望，更新参数估计：$\theta^{t+1}=arg max_{\theta}Q(\theta|\theta^t)$



### 问题5： CLIP算法的框架



<h2 id="8.CVer整理">8.CVer整理</h2>

### 问题1：TensorRT优化的流程

1. [**模型转换**：首先，您需要将预训练的 PyTorch 模型转换为 ONNX 格式。这可以通过两种方案实现：pytorch -> onnx -> engine 或者 pytorch -> wts -> engine](https://blog.csdn.net/weixin_44742084/article/details/126518991)[2](https://blog.csdn.net/weixin_44742084/article/details/126518991).
2. **导入 ONNX 模型**：将 ONNX 模型导入到 TensorRT 中。这一步包括从磁盘加载 ONNX 文件，并将其转换为 TensorRT 网络。
3. **应用优化并生成引擎**：使用 TensorRT 的 builder 对象，根据输入模型、目标平台和其他配置参数，构建优化的 TensorRT 引擎。这个引擎将针对特定硬件进行优化，以提高性能。
4. **执行推理**：最后一步是向 TensorRT 引擎提供输入数据，执行推理并获取输出结果。



### 问题3： 密集行人检测遮挡问题怎么解决

论文：Repulsion Loss: Detecting Pedestrians in a Crowd

链接： https://arxiv.org/abs/1711.07752

思路：使得预测框更加接近所负责的真实目标框，而远离周围的目标。

$L=L_\text{Attr}+\alpha*L_\text{RepGT}+\beta*L_\text{RepBox},\quad(1)$

$L_{\mathrm{Attr}}=\frac{\sum_{P\in\mathcal{P}_+}\mathrm{Smooth}_{L_1}(B^P,G_{Attr}^P)}{|\mathcal{P}_+|}$

$L_{\mathrm{RepGT}}=\frac{\sum_{P\in\mathcal{P}_+}\text{Smooth}_{ln}\left(IoG(B^P,G_{Rep}^P)\right)}{\left|\mathcal{P}_+\right|}$

$\left.\text{Smooth}_{ln}=\left\{\begin{array}{ll}-\ln\left(1-x\right)&x\leq\sigma\\\\\frac{x-\sigma}{1-\sigma}-\ln\left(1-\sigma\right)&x>\sigma\end{array}\right.\right.$

$L_{\mathrm{RepBox}}=\frac{\sum_{i\neq j}\mathrm{Smooth}_{ln}\left(IoU(B^{P_i},B^{P_j})\right)}{\sum_{i\neq j}1[IoU(B^{P_i},B^{P_j})>0]+\epsilon}$



### 问题4：为什么U-Net在医学图像上表现好

U-Net最关键的、也是最特色的部分在于**Skip Connection**。每一次下采样都会有一个跳跃连接与对应的上采样进行级联，这种不同尺度的特征融合对上采样恢复像素大有帮助，具体来说就是高层(浅层)下采样倍数小，特征图具备更加细致的图特征，底层(深层)下采样倍数大，信息经过大量浓缩，空间损失大，但有助于目标区域(分类)判断，当high level和low level的特征进行融合时，分割效果往往会非常好。



### 问题5： 自动驾驶中检测模型如何针对Corner case优化

自动驾驶中coner case的定义

- 传感器级别：硬件原因和外部环境的干扰导致，比如镜头等光学器件的损坏，表面的污迹等造成成像偏差。
- 数据内容级别：
  - 域级： 驾驶环境变换后，激光雷达无法理解不同道路的形状；使用国家变换后，摄像头在不同国家输入的内容让算法产生歧义；毫米波雷达在遇天气环境变化后，比如雨雪，会产生虚检
  - 目标级：激光雷达的点云输入会受灰尘、蚊虫的影响，产生未定义的目标；摄像头的输入出现某种为定义的动物；毫米波雷达的特性可能会导致丢失低速的目标；
  - 场景级：激光雷达的上下文异常,比如停放在人行横道上的清扫车；摄像头输入的内容中，发现一个人离地面很高，实际情况可能是在广告牌上的人；毫米波雷达所检测到的目标太多，实际可能是路上的灌木造成。
- 交通参与者超预期问题

**解决方案：**

- 置信度(Confidence score)：通过神经网络估计不确定coner case的置信的，确定是否是异常情况。

- 重建(Reconstructive):对异常对象进行重建，或者仿真模拟得出异常对象数据，加入模型训练。

- 生成coner case（Generative):对异常对象和数据进行扩充，利用GAN等技术生成扩充的coner case案例。

- 特征抽取coner case(Feature Extraction):利用聚类或者svm等分类算法，对coner case案例进行快速的定位。

- 预测补充coner case(Prediction):利用前后帧之间运动物体不会凭空消失或突变等，进行异常情况的校正回归(陈时中直呼内行)。



### 问题6： 训练网络时怎么判断有没有过拟合、欠拟合

- 过拟合（over-fitting），机器学习模型或者是深度学习模型在训练样本中表现得过于优越，导致在验证数据集以及测试数据集中表现不佳。也就是泛化误差比较大，泛化能力差。
- 欠拟合是指模型不能在训练集上获得足够低的误差，模型复杂度低，模型在训练集上就表现很差，没法学习到数据背后的规律。

看训练集合验证集随着样本数量的增加，他们之间的差值变化。如果训练集和测试集的准确率都很低，那么说明模型欠拟合；如果训练集的准确率接近于1而验证集还相差甚远，说明模型典型的过拟合。



### 问题7： GBDT和Adaboost的区别

各类 Boost 方法是基于树模型的集成模型。

- Adaboost的基本思想是：
  - 通过不断修改样本权重（增大分错样本的权重，降低分对样本的权重），达到自适应调整样本权重的效果。
  - 将弱分类器组合成一个强分类器：加权多数表决（加大分类误差率小的弱分类器的权值，减小分类误差率大的弱分类器的权值）。

- GBDT
  - 采用梯度下降法，每一次迭代都是为了优化当前损失函数，进而在损失函数减少（负梯度，即一阶导数的反方向）的方向上建立一个新的模型。
  - 当损失函数选择为“均方损失”时候，其沿着负梯度方向拟合，实质上就是拟合残差
- XGBoost
  - XGBoost 的 boosting 策略则与 GBDT 类似，均是在新加入的基分类器进一步拟合预测值与真实值之间的差异（不一定是残差），只不过 GBDT 是沿着负梯度的方向进行拟合，只用到了一阶梯度信息，而 **XGBoost 则是对损失函数进行二阶泰勒展开**，相比于 GBDT，其拟合方向更准、速度更快。



### 问题8： 神经网络的初始化方法

- **是否可以将权重初始化为0？**     不可以，如果所有的参数都为0，那么神经元的输出都将会相同，那么在BP的时候同一层的神经元学到的东西相同，gradient相同，weight update也相同。
- **pre-training:** 选择一个已经训练好的在任务A上的模型（称为pre-trained model），将其放在任务B上做模型调整（称为fine-tuning）。

- **随机初始化：**随机初始化的缺点，np.random.randn()其实是一个均值为0，方差为1的高斯分布中采样。当神经网络的层数增多时，会发现越往后面的层的激活函数（使用tanH）的输出值几乎都接近于0。
- **Xavier：**为了解决随机初始化的问题提出来的另一种初始化方法,**适用于 sigmoid 和 tanh 激活函数**，尽可能的让输入和输出服从相同的分布，这样就能够避免后面层的激活函数的输出值趋向于0。但是这种初始化方式对于ReLU激活函数不起作用。公式为$W\sim\mathcal{N}(0,\sqrt{\frac{2}{n_{in}+n_{out}}})$
- **HE:**一种针对ReLU的初始化方法。公式为$W\sim\mathcal{N}(0,\sqrt{\frac{2}{n_{in}}})$​



### 问题9：DETR中匈牙利匹配算法的具体流程

- DETR的核心：目标检测的end-to-end框架，输入的是一张图像，输出的直接是最后的预测标注结果，不再需要后处理（nms非极大值抑制）。因为nms对于模型的调参比较复杂。而且因为不是所有的硬件都支持这nms，所有即使训练好了模型，部署起来也比较困难。

- DETR的训练：
  - 用卷积神经网络抽特征
  - 用Transformer Encoder去学全局特征，帮助后面做检测
  - 用Transformer Decoder调整object query生成100个预测框
  - 用输出的100个object query框和ground truth框做一个匹配，然后在一一配对好的框中去计算目标检测的loss（分类loss与回归loss）
- DETR的推理：其和训练过程的前3步都是一致的，直接在最后的输出上用一个阈值卡一下模型的置信度。然后最后模型置信度高的（置信度大于0.7）预测就会被保留下来。
- DETR的二分图匹配：
  - 规约：
    - 行规约（每一行减去该行最小值）
    - 列规约（每一列减去该列最小值）
  - 试指派
    - 找到含0数目最少的行或列(不妨取行) 随后将该行第一个零置为“T0”,随后将“T0”所在行和列中其他的零置“F0”。依次类推，完成归约矩阵所有行的操作。
    - 用最少的直线来覆盖矩阵中所有的零。

```python
from scipy.optimize import linear_sum_assignment
...
# 匈牙利算法实现二分图匹配
class HungarianMatcher(nn.Module):
    """This class computes an assignment between the targets and the predictions of the network
    For efficiency reasons, the targets don't include the no_object. Because of this, in general,
    there are more predictions than targets. In this case, we do a 1-to-1 matching of the best predictions,
    while the others are un-matched (and thus treated as non-objects).
    """
    def __init__(self, cost_class: float = 1, cost_bbox: float = 1, cost_giou: float = 1):
        """Creates the matcher
        Params:
            cost_class: This is the relative weight of the classification error in the matching cost
            cost_bbox: This is the relative weight of the L1 error of the bounding box coordinates in the matching cost
            cost_giou: This is the relative weight of the giou loss of the bounding box in the matching cost
        """
        super().__init__()
        self.cost_class = cost_class
        self.cost_bbox = cost_bbox
        self.cost_giou = cost_giou
        assert cost_class != 0 or cost_bbox != 0 or cost_giou != 0, "all costs cant be 0"
    @torch.no_grad()
    def forward(self, outputs, targets):
        """ Performs the matching
        Params:
            outputs: This is a dict that contains at least these entries:
                 "pred_logits": Tensor of dim [batch_size, num_queries, num_classes] with the classification logits
                 "pred_boxes": Tensor of dim [batch_size, num_queries, 4] with the predicted box coordinates
            targets: This is a list of targets (len(targets) = batch_size), where each target is a dict containing:
                 "labels": Tensor of dim [num_target_boxes] (where num_target_boxes is the number of ground-truth
                           objects in the target) containing the class labels
                 "boxes": Tensor of dim [num_target_boxes, 4] containing the target box coordinates
        Returns:
            A list of size batch_size, containing tuples of (index_i, index_j) where:
                - index_i is the indices of the selected predictions (in order)
                - index_j is the indices of the corresponding selected targets (in order)
            For each batch element, it holds:
                len(index_i) = len(index_j) = min(num_queries, num_target_boxes)
        """
        bs, num_queries = outputs["pred_logits"].shape[:2]
        # We flatten to compute the cost matrices in a batch
        out_prob = outputs["pred_logits"].flatten(0, 1).softmax(-1)  # [batch_size * num_queries, num_classes]
        out_bbox = outputs["pred_boxes"].flatten(0, 1)  # [batch_size * num_queries, 4]
        # Also concat the target labels and boxes
        tgt_ids = torch.cat([v["labels"] for v in targets])
        tgt_bbox = torch.cat([v["boxes"] for v in targets])
        # Compute the classification cost. Contrary to the loss, we don't use the NLL,
        # but approximate it in 1 - proba[target class].
        # The 1 is a constant that doesn't change the matching, it can be ommitted.
        cost_class = -out_prob[:, tgt_ids]
        # Compute the L1 cost between boxes
        cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)
        # Compute the giou cost betwen boxes
        cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox))
        # Final cost matrix
        C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou
        C = C.view(bs, num_queries, -1).cpu()
        sizes = [len(v["boxes"]) for v in targets]
        indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes, -1))]
        return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]
```



### 问题10： 为什么transformer中要用LayerNorm

- 使用LN保留了同一样本内部特征的大小关系，因此更有利于Transformer模型（注意力机制）捕捉全局信息。
- 稳定训练：LayerNorm通过规范化每个样本在层内的特征分布来稳定梯度，这有助于避免梯度消失或爆炸。
- 减少内部协变量偏移：当一个模型的前向传播过程中参数发生变化时，会导致后续层接收到的数据分布变化，即内部协变量偏移。LayerNorm通过在每个层内独立地对数据进行规范化处理，减少了这种影响。



### 问题11： 为什么self-attention可以堆叠多层，有什么作用

- 加深模型表示能力：每一层Self-Attention可以专注于捕获不同级别的抽象特征，从低级的局部关系到高级的全局上下文信息。
- 增强特征交互：每一层Self-Attention都可以根据前一层的结果重新分配注意力权重。注意力机制可以在不同层之间迭代地调整其焦点，从而更好地捕捉到输入序列中的复杂依赖关系。
- 增加模型容量：堆叠更多的Self-Attention层增加了模型的参数数量，这为模型提供了更大的容量去拟合复杂的函数映射。



### 问题12： 介绍常用的聚类算法(KMeans,DBSCAN, Mean shift)

- KMeans：一个数据放进来，需要*指定K值*，来声明要得到簇的个数，通过目标函数进行不断地优化、求解$\mathrm{min\sum_{i=1}^{K}\sum_{{x\in C_{i}}}dist(c_{i},x)^{2}}$

  - 优点：简单
  - 缺点：K值难以确定，初始点影响打，复杂度与样本呈线性相关

- DBSCAN：基于密度的噪声应用空间聚类，变量定义为：

  - 核心对象：若某个点的密度达到算法设定的阈值则其为核心点（即 **r 邻域**内点的数量不小于 **minPts**）
  - ϵ-邻域的距离阈值：设定的半径r
  - 直接密度可达：若某点 p 在点 q 的 r 邻域内，且 q 是核心点则 p − q 直接密度可达
  - 密度相连：若从某核心点 p 出发，点 q 和点 k 都是密度可达的，则称点 q和点 k 是密度相连的
  - 边界点:属于某一个类的非核心点，在往某个方向扩展时，到了没有边界点的地方，就停止了这个方向（即密度不可达）
  - 噪声点：不属于任何一个类簇的点，从任何一个核心点出发都是密度不可达的
  - 优点：不需要指定k，擅长找到离群点
  - 缺点：高维数据处理困难，参数对结果影响很大

  ![DBSCAN算法描述](assets/88d7d7f05142a7fe142509af89bc475c-1722866543167-3.png)



### 问题13：Canny算子的流程

- 高斯平滑，滤除噪声
- 计算每点的梯度强度$G=\sqrt{G_x^2+G_y^2}$， 和方向$\theta=arc\tan\bigl(G_y/G_x\bigr)$
- 采用非极大值抑制，将当前像素的梯度强度与沿正负梯度方向上的两个像素进行比较，如果当前像素的梯度强度与另外两个像素相比最大，则该像素点保留为边缘点，否则该像素点将被抑制。
- 双阈值检测：存在由于噪声和颜色变化引起的一些边缘像素。从而确定**被抑制的边缘，弱边缘和强边缘**。
- 抑制孤立低阈值点：针对弱边缘，查看周围8邻域有没有强边缘点，有则保留。



### 问题14： NMS的缺点及其改进工作

- NMS的缺点：
  - 硬阈值：标准NMS使用固定的阈值来判断两个框是否重叠太多，这可能导致某些情况下重要物体被错误地抑制掉。
  - 忽略上下文：基本NMS算法仅基于重叠程度和置信度得分来决定保留哪些框，忽略了上下文信息，如物体的形状、大小或背景。
  - 顺序敏感性：NMS通常按照置信度得分排序候选框，然后逐个检查和抑制。
  - 处理密集对象时的局限性：当场景中有大量密集排列的对象时，NMS可能无法正确处理这些情况，因为它倾向于只保留一个框。
  - 效率问题：对于大规模检测任务，NMS可能成为瓶颈，尤其是在处理大量候选框时。
- Soft-NMS：一种软化NMS阈值的方法，它不是简单地删除重叠的边界框，而是降低它们的得分。这样可以避免硬阈值带来的问题，并且更平滑地处理重叠框。
- Weighted-NMS：通过给重叠框加权来合并它们的信息，而不是直接删除其中一个。
- Cluster-NMS：Cluster-NMS采用聚类方法来处理重叠的边界框，将相似的框分组在一起，然后从中选择代表框。



### 问题15： 怎么判断连通域是否相邻

图的深度优先或者广度优先遍历



### 问题16：分割Segmentation和抠图Matting的区别

- 图像分割旨在将图像划分为多个有意义的区域或对象。
- 抠图则是指从图像中精确提取一个对象（通常是前景），并保留其边缘细节。抠图通常涉及估计对象的透明度（alpha matte），以便可以将该对象无缝地放置到新的背景上。抠图的一个关键挑战是处理半透明物体（如头发、烟雾等）的边缘细节。

- 区别：
  - **分割**：输出是一个掩膜，其中每个像素都有一个类别标签。**抠图**：输出是一个alpha matte，通常是一个灰度图像，其中每个像素的值表示该像素的不透明度，范围从0（完全透明）到1（完全不透明）。
  - **分割**：主要关注如何准确地区分不同的物体类别。**抠图**：更注重细节处理，尤其是处理物体边缘的精细结构和半透明效果。



### 问题17： 介绍SVM和逻辑回归

- SVM：支持向量机是一种二分类模型，其基本思想是找到一个决策边界（超平面），使得两类样本尽可能地分开，同时使这个决策边界到最近的样本点的距离最大化。这个距离称为间隔（Margin），最大化间隔可以提高模型的泛化能力。
- 逻辑回归实际上是一种用于解决分类问题的线性模型。它的目标是估计样本属于某一类的概率。逻辑回归模型使用逻辑函数（Sigmoid函数）将线性回归模型的输出转换为概率值。

SVM寻找最大间隔的决策边界，而逻辑回归通过概率估计来确定决策边界。SVM优化间隔，逻辑回归优化对数似然函数。



### 问题18： 如何检测未知目标

- **Autoencoders**：通过训练自动编码器来重建输入图像，那些重建误差较大的样本被认为是异常的。

- **聚类：**使用聚类算法（如K-means、DBSCAN等）对图像中的对象进行分组，未知目标可能会形成单独的聚类或与其他聚类显著不同。
- **开放世界识别：**通过估计每个类别的最大似然估计来调整模型的输出，以识别未知类别。



### 问题19：多卡的BN如何实现同步

在单个GPU上训练时，BN层通常使用该GPU上的mini-batch统计数据来进行归一化。然而，在多GPU或多机器分布式训练场景中，如果每个GPU都独立计算BN统计数据，则会导致不同的BN效果，这可能会降低模型的性能。

同步BN会在每个训练步骤中收集所有GPU上的mini-batch统计数据，并使用这些统计信息来计算全局平均值和方差。

在PyTorch中，可以通过`torch.nn.SyncBatchNorm`模块来轻松实现同步BN。



### 问题20： 图像边缘检测算子有哪些

- Sobel算子：包括两个3×3的卷积核，一个用于检测水平边缘，另一个用于检测垂直边缘。

  - 水平梯度$\begin{bmatrix}-1&0&+1\\-2&0&+2\\-1&0&+1\end{bmatrix}$

  - 垂直梯度$\begin{bmatrix}-1&-2&-1\\0&0&0\\+1&+2&+1\end{bmatrix}$

- Prewitt算子：Prewitt算子与Sobel算子类似，但使用稍微不同的3×3卷积核。

  - 水平梯度$\begin{bmatrix}-1&0&+1\\-1&0&+1\\-1&0&+1\end{bmatrix}$

  - 垂直梯度$\begin{bmatrix}-1&-1&-1\\0&0&0\\+1&+1&+1\end{bmatrix}$

- Roberts算子：Roberts算子使用2×2的卷积核来检测图像中的边缘。
  - 水平梯度：$\begin{bmatrix}0&+1\\-1&0\end{bmatrix}$
  - 垂直梯度：$\begin{bmatrix}+1&0\\0&-1\end{bmatrix}$
- 拉普拉斯算子：用于检测图像中强度的局部极值。
  -  $\begin{bmatrix}0&-1&0\\-1&4&-1\\0&-1&0\end{bmatrix}$​



### 问题21： 各种回归损失的计算以及优缺点

- 均方误差：MSE是最常用的回归损失函数之一，它计算预测值与真实值之间的平方差的均值。$\mathrm{MSE}=\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}$
  - 优点：简单直观，容易理解和实现。梯度平滑，便于优化。
  - 缺点：对异常值（outliers）非常敏感，因为平方项会放大误差。
- 均方根误差：RMSE是MSE的平方根，它将MSE的单位恢复为原始输出的单位。
  - 优点：与MSE相比，RMSE更容易解释，因为它与输出值在同一尺度上。
  - 缺点：对异常值敏感
- 平均绝对误差MAE：$\mathrm{MAE}=\frac{1}{n}\sum_{i=1}^{n}|y_{i}-\hat{y}_{i}|$
  - 优点：不像MSE那样受异常值的影响大。更能反映实际预测误差。
  - 缺点：梯度不平滑（在0处不可导），这可能会使优化过程更加困难。当误差较大时，MAE不如MSE敏感，可能无法充分反映预测误差的重要性。
- Huber损失（Smooth  L1 Loss）：$\begin{aligned}&\text{Huber Loss}=\begin{cases}\frac12(y_i-\hat{y}_i)^2&\mathrm{if~}|y_i-\hat{y}_i|<\delta\\\delta(|y_i-\hat{y}_i|-\frac12\delta)&\mathrm{otherwise}&\end{cases}\end{aligned}$
  - 优点：对异常值的鲁棒性较好。梯度平滑，便于优化。
  - 缺点：需要调整超参数δ，以平衡对异常值的敏感性和鲁棒性。



### 问题22： Transformer相比于CNN的优缺点

- Transformer优点：
  1. **全局信息关系建模：** Transformer 通过自注意力机制（self-attention）能够捕捉输入序列中各个位置之间的依赖关系，能够更好地建模长距离依赖关系。
  2. **可并行性：** Transformer 模型中的自注意力层可以并行计算，使得在某种程度上更容易实现并行化处理，因此在一定情况下速度可能更快。
  3. **适用于序列任务：** 原本设计用于处理序列数据（如自然语言处理任务），在某些图像任务中也能够应用，特别是对于具有空间关系的图像数据。
- Transformer缺点：
  1. **计算和内存消耗大**： Transformer 模型的自注意力机制需要大量的计算资源和内存，对于大规模的图像数据，可能需要巨大的模型和计算能力，使得其在实际应用中可能受到限制。
  2. **特征提取能力相对较弱：** 对于基于图像像素级别的特征提取，Transformer 相对传统的[卷积神经网络](https://so.csdn.net/so/search?q=卷积神经网络&spm=1001.2101.3001.7020)可能效果不如。



### 问题23： LN和BN

- 动机：对数据做归一化处理——也就是对数据以某个角度或者层面做0均值1方差的处理。独立同分布的数据可以简化模型的训练以及提升模型的预测能力。内部量偏移：每一层的参数更新都会导致上层的输入数据在输出时分布规律发生了变化，并且这个差异会随着网络深度增大而增大。
- 原理：BN把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，其实就是把越来越偏的分布强制拉回比较标准的分布。这样让梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。经过BN后，目前大部分Activation的值落入非线性函数的线性区内，其对应的导数远离导数饱和区，这样来加速训练收敛过程。
- BN与LN的不同
  1. BN针对的是同一个batch内的所有数据，而LN则是针对单个样本。
  2. BN是对同一batch内的数据的同一纬度做归一化，因此有多少维度就有多少个均值和方差；而LN则是对单个样本的所有维度来做归一化，因此一个batch中就有batch_size个均值和方差。
  3. 因此，BN对batch比较敏感，batch_size不能太小；LN则是独立于batch_size的
- BN的优点：加快神经网络的训练时间。容忍更高的学习率（learning rate）和初始化权重更容易。可以支持更多的损失函数。BN在一定的程度上起到了dropout的作用。
- BN的缺点：BN对于batch_size的大小还是比较敏感的，batch_size很小的时候，其梯度不够稳定；BN对于序列网络，RNN、lstm等模型的效果并不好。
- LN的优点：LN能够很好的应用在RNN、lstm等类似的网络上；对batch_size的大小并不敏感。
- Transformer中为什么不用BN：
  1. LN是针对每一句话做归一化处理，没有破坏一句话内在语义的联系；
  2. layer normalization 有助于得到一个球体空间中符合0均值1方差高斯分布的 embedding
  3. layer normalization可以对transformer学习过程中由于多词条embedding累加可能带来的“尺度”问题施加约束，相当于对表达每个词一词多义的空间施加了约束，有效降低模型方差。



### 问题24：介绍RLHF

1. 预训练一个语言模型 (LM) ；
2. 聚合问答数据并训练一个奖励模型 (Reward Model，RM) ；
3. 用强化学习 (RL) 方式微调 LM。

- **预训练语言模型：**OpenAI 在其第一个流行的 RLHF 模型 [InstructGPT](https://openai.com/blog/instruction-following/) 中使用了较小版本的 GPT-3; Anthropic 使用了 1000 万 ～ 520 亿参数的 Transformer 模型进行训练；DeepMind 使用了自家的 2800 亿参数模型 [Gopher](https://arxiv.org/abs/2112.11446)。

- **训练奖励模型：**

  - RM 的训练是 RLHF 区别于旧范式的开端。这一模型**接收一系列文本并返回一个标量奖励**，数值上对应人的偏好。
  - RM 可以是另一个经过微调的 LM，也可以是根据偏好数据从头开始训练的 LM。
  - RM 的提示 - 生成对文本是从预定义数据集中采样生成的，并用初始的 LM 给这些提示生成文本。
  - 关于训练奖励数值方面，这里需要**人工对 LM 生成的回答进行排名**。起初我们可能会认为应该直接对文本标注分数来训练 RM，但是由于标注者的价值观不同导致这些分数未经过校准并且充满噪音。通过排名可以比较多个模型的输出并构建更好的规范数据集。
  - 具体的排名方式，一种成功的方式是对不同 LM 在相同提示下的输出进行比较，然后使用 [Elo](https://en.wikipedia.org/wiki/Elo_rating_system) 系统建立一个完整的排名。
  - 偏好模型和生成模型需要具有类似的能力来理解提供给它们的文本。

  ![reword model](assets/reward-model.png)

- **用强化学习微调：**

  使用策略梯度强化学习 (Policy Gradient RL) 算法、近端策略优化 (Proximal Policy Optimization，PPO) 微调初始 LM 的部分或全部参数。首先，该 **策略** (policy) 是一个接受提示并返回一系列文本 (或文本的概率分布) 的 LM。这个策略的 **行动空间** (action space) 是 LM 的词表对应的所有词元 (一般在 50k 数量级) ，**观察空间** (observation space) 是可能的输入词元序列，也比较大 (词汇量 ^ 输入标记的数量) 。**奖励函数** 是偏好模型和策略转变约束 (Policy shift constraint) 的结合。

  PPO 算法确定的奖励函数具体计算如下：将提示 *x* 输入初始 LM 和当前微调的 LM，分别得到了输出文本 *y1*, *y2*，将来自当前策略的文本传递给 RM 得到一个标量的奖励 $r_\theta$。将两个模型的生成文本进行比较计算差异的惩罚项，该惩罚项为输出词分布序列之间的 Kullback–Leibler [(KL) divergence](https://en.wikipedia.org/wiki/Kullback–Leibler_divergence) 散度的缩放，即$r=r_\theta -λr_{KL}$。

  ![PPO](assets/rlhf.png)

  

### 问题25：介绍MoE和变体



### 问题26：介绍LoRA和变体



### 问题27： LoRA参数更新的机制



### 问题28： 如何减轻LLM中的幻觉现象



### 问题29： MLM和MIM的关系和区别



### 问题30： Stable Diffusion的技术原理



### 问题31： 解决LLM Hallucination的方法



### 问题32： Occupancy预测的出发点是什么



### 问题33： 介绍RWKV，Mamba和Mamba v2



### 问题34： 2D图像预训练怎么迁移到3D点云任务



### 问题35： 为什么现在的LLM都是decoder-only架构



### 问题36： Transformer训练深有什么问题，怎么解决



### 问题37： 现在车道线检测的主流的loss是什么?你有哪些想法?



### 问题38： 如何让 LLM基于 query和 context得到高质量的response



### 问题39： 为什么GAN中经常遇到mode collapse，而Diffusion比较少?



### 问题40： 位置编码有哪些？



### 问题41： **ViT为什么要分patch？**



### 问题42： **Transformer训练和部署技巧**



### 问题43： **介绍自注意力机制和数学公式**



### 问题44： **介绍Transformer的Encoder模块**



### 问题45： **介绍Transformer的Decoder模块**



### 问题46： **Transformer和Mamba（SSM）的区别**



### 问题47： **Transformer中的残差结构以及意义**



### 问题48： **为什么Transformer适合多模态任务？**



### 问题49： **Transformer的并行化体现在哪个地方？**



### 问题50： **Transformer为什么使用多头注意力机制？**



### 问题51： **Transformer训练的Dropout是如何设定的？**



### 问题52： **Transformer 模型中的自注意力机制是如何工作的？**



<h2 id="9.牛客整理">9.牛客整理</h2>

### 问题1： BERT和GPT的区别，分别的优势



### 问题2： 大模型的发展趋势



### 问题3： 介绍一下flash attention



### 问题4： 介绍一下group query attention



### 问题5： dense特征和sparse特征的区别是什么



### 问题6： mapreduce如何做10亿个数字的全局排序



### 问题7： RNN、LSTM、Transformer的区别



### 问题8：MMOE，PLE框架介绍



### 问题9： LightGBM和XGBoost的区别



### 问题10： XGBoost原理讲解



### 问题11： 随机森林如何保证每个树的随机性



### 问题12： MMoE如何保证每个专家的随机性



### 问题13： multi-head attention如何保证每个head的随机性



### 问题14： bagging和boosting的区别



### 问题15： 介绍卷积 激活 池化 全连接层含义



### 问题16： 什么情况下可以不使用池化层



### 问题17： 决策树怎么划分特征



### 问题18： 随机森林有两种随机方式 怎么体现



### 问题19： 线性模型和非线性模型的优缺点



### 问题20： 样本数量小且特征数量多时 使用线性还是非线性模型



### 问题21： 离散特征的处理方式



